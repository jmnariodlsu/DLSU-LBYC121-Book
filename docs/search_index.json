[["index.html", "LBOMETR Course Book 1 Introduction 1.1 About Me", " LBOMETR Course Book Jem Marie M. Nario 2026-01-23 1 Introduction Welcome to the LBOMETR Course Book! This book is designed to guide students through the course by providing all necessary resources, materials, and instructions. LBOMETR This course book is intended to ensure that DLSU Carlos L. Tiu-School of Economics students will be able to learn more about Econometrics using R. You will find sections on the syllabus, course assessments, and group projects, as well as guidance for navigating the course effectively. 1.1 About Me My name is Jem Marie M. Nario, and I am your lecturer for this course. I am excited to guide you through this journey of learning and discovery since I am also on a journey of learning and discovery while teaching part-time. This book is a trial version whnb ich will be updated along the course as it also serves as a practice for me. Email: jem.nario@dlsu.edu.ph LinkedIn: linkedin.com/in/jmnario/ Feel free to reach out with any questions or concerns throughout the course. "],["syllabus.html", "2 Syllabus 2.1 General Course Description 2.2 Specific Course Description 2.3 Final Course Outputs 2.4 Generative AI-Use Policy 2.5 Classroom Policies", " 2 Syllabus 2.1 General Course Description This course introduces Economics majors to more advanced commands and techniques used in econometric software package R commonly used in empirical research. 2.2 Specific Course Description This course familiarizes Economics majors with advanced techniques in R for empirical research. Students will also gather and analyze their own real-world data to investigate a specific economic problem, applying econometric methods and presenting their findings in a final project. 2.3 Final Course Outputs CLOs Output Due Date CLO 1,2,4 Data Storytelling (OR) Week 10 CLO 1-4 Data Story Archive (PF/PR) 18:00 Tuesday Week 14 CLO 1-3 Problem Sets (QA) 18:00 Weeks 6 and 12 CLO 1,3 Short Quizzes (QA) Weeks 2-6, 8, 11-12 CLO 4 Class Participation (TW/OB) Weeks 1-12 2.4 Generative AI-Use Policy For each component of the final grade defined above, students must identify the generative AI usage policy level. The levels are: Free to Use – AI may be used without restriction. Allowed in Specific Contexts – AI may be used only for clearly defined purposes and must be cited. Banned – AI use is strictly prohibited. Grade Component Usage Policy Level Notes Data Storytelling (OR) Allowed in Specific Contexts Students may use generative AI only to brainstorm ideas, create outlines, and design slides. AI must not be used to generate or check final code or analysis. Data Story Archive (PF/PR) Banned AI use is strictly prohibited for writing, coding, or analyzing the archive. Work must reflect independent technical skill. Problem Sets (QA) Banned Students must independently write and debug code; AI may not generate or check solutions. Short Quizzes (QA) Banned AI use is not allowed during quizzes. Class Participation (TW/OB) Banned All participation must be based on students’ own understanding and contributions. This course is an applied coding and econometrics laboratory, designed to develop students’ ability to analyze real-world data, write reproducible code, and interpret econometric results independently. To support student learning and promote the responsible use of emerging technologies, students may use generative AI tools (e.g., ChatGPT, Gemini, etc.) only for conceptual or exploratory coding assistance, such as: ● Understanding function syntax or usage ● Exploring coding strategies ● Learning general debugging approaches The use of generative AI is strictly prohibited for the following: ● Generating or checking final code for the Data Story Archive (report and code) ● Generating or checking code for Problem Sets ● Short quizzes ● Any submission intended to reflect independent technical skill Overreliance on AI may hinder students’ understanding of key concepts, which are essential to success in this course. Any unauthorized use of AI will be treated as academic dishonesty, in accordance with the university’s academic integrity policy. Students are encouraged to consult the instructor if they are unsure about the appropriate use of AI for specific tasks. 2.5 Classroom Policies 1. Assessments All major assessments are described below. Deadlines, formats, and submission requirements are non-negotiable. Assessment Format &amp; Submission Notes Short Quizzes In-class, 2 coding questions per session. Students work with a buddy to check each other’s answers. Each student underlines economic theory and econometric reasoning in their buddy’s paper and places check marks for each. No quizzes on Weeks 6,7, 8, 9, 10, 12, 13, 14. Problem Set 1 Group submission (hard copy). Handwritten discussion + typed step-by-step R code + printed/pasted graphs. Covers material up to descriptive statistics. Due Week 6. Questions are provided on Day 1 in the LBOMETR Course Book. Problem Set 2 Group submission (hard copy). Handwritten discussion + typed step-by-step R code + printed/pasted graphs. Covers material from descriptive statistics to formal tests of assumptions. Due Week 12. Questions are provided on Day 1 in the LBOMETR Course Book. Data Storytelling (Oral Presentation) Group presentation in HyFlex classroom. Must include R visualizations and clear explanation of methodology, results, and conclusions. Graded individually, based on contribution, clarity, and engagement. Data Story Archive Group submission (hard copy) compiling R scripts, analyses, visualizations, and interpretations. Demonstrates independent mastery; must be concise, reproducible, and complete. AI or outside generation is not allowed. Hard copy must be submitted by Week 14. 2. Groupings Students will be divided into 5 groups of 6 on the first day of class. Groups are assigned based on in-class skill surveys: comfort with R and economic theory. Groups remain fixed throughout the semester. Roles (e.g., introduction, data cleaning, analysis, visualization, discussion) may rotate within the group for fairness, except for the assigned monitor if used. 3. Appointments &amp; Consultations Data Story Topic Consultation: Groups must meet with the professor before Week 5. Topic, methodology, or scope changes after Week 6 without notice will incur a 50% deduction on the Data Story grade. Mock Presentation &amp; Archive Consultation: Groups are encouraged to schedule 15-minute in-person sessions after Mock Presentation submission to improve the Data Story Archive. Slots are booked via a provided link. Other Consultations: Can be done via email. Lecturer responds only between 8 AM – 6 PM. 4. Grading Notes Perfect scores (100%) are very rare. Excellent students typically achieve up to ~95%. Grades reflect demonstrated mastery, quality of outputs, and adherence to rubrics. Attendance, participation, buddy system compliance, and group contributions are part of the class participation grade. No general incentives or extra credit are provided. 5. Class Monitor Responsibilities One student monitor per session, rotating weekly or biweekly, will oversee the buddy system. Responsibilities: Collect all buddy-checked papers after class. Record for each student: Buddy’s name who checked the paper. Number of checks received (0, 1, or 2). Ensure all buddy system procedures are followed (underlines and check marks). Submit a tally sheet to the professor by 6 PM of class day. Important: The monitor does not grade anything. Failure to follow these steps may affect participation points for the monitor or the class. 6. Attendance Attendance is monitored during in-person sessions. Attendance points contribute to class participation. Unexcused absence will not be able to have full marks in class participation and might miss short quizzes. Excused absence: no deduction (documentation required). 7. Buddy System Students must complete buddy checks for short quizzes as described in Section 1. Compliance is verified by the class monitor and reflected in participation scores. 8. Problem Sets Students are expected to complete and submit the assigned problem sets on time, including discussion, code, and visualizations as described above. 9. Data Storytelling &amp; Data Story Archive Follow all guidelines for oral presentations and written archive submissions, including hard copy submission and proper documentation of R code. Consultations are highly recommended to refine presentations and archive outputs. 10. Use of Course Materials All learning and teaching materials provided in this class are for the exclusive use of students enrolled in this course, Term 2, AY2025-26. Students are not allowed to upload, share, or distribute these materials publicly or to anyone other than their groupmates/classmates without the instructor’s permission. 2.5.1 EXCUSED ABSENCES POLICY: Students must process requests for excused absences from their respective Associate Deans. For SOE students, the Associate Dean of the School of Economics will only process requests for excused absences due to medical and mental health reasons. Covid-related leave requests are no longer accepted as of August 30, 2023. Students must provide official documentation from the Office of Student Affairs (OSA) for absences related to official university functions.  Procedure: Timing: Submit requests immediately upon returning to campus and no later than seven working days from the return date.  Request Letter: Write a letter to the Associate Dean including: ○ Course details (course name, section, faculty names, and emails) ○ Dates of absence(s) ○ Reason for absence with relevant details Supporting Documents: Attach validated documents from the appropriate university offices. Submission: Combine the letter and supporting documents into a single PDF and upload viathis form. Approved absences will be communicated to you and your professors within three working days. Note that processing is done only during regular weekday office hours.  Important: Only complete requests will be processed. Falsifying records is a major offense as per the Student Handbook (Section 9, pp. 85-87). Note: The syllabus is unique to the course per Term, per AY. Final syllabus uploaded in Animospace. "],["course-assessments.html", "3 Course Assessments 3.1 Short Quizzes 3.2 Problem Sets (1 and 2) 3.3 Data Storytelling 3.4 Data Story Archive 3.5 Participation 3.6 Grading System 3.7 Grading Scale", " 3 Course Assessments 3.1 Short Quizzes Format: In-class, handwritten, two questions per session. Questions involve: Coding: Write R code to solve the problem. Discussion: Explain your solution in terms of: Economic theory behind the answer. Econometric reasoning (why variables/methods were chosen). Visuals can be shown to your buddy, who will check your work. Buddy System: Each student pairs with a seatmate to verify the discussion: Underline economic theory and econometric reasoning in peer’s paper. Place a check for each component found. Class Monitor Responsibilities One student monitor per session, rotating weekly or biweekly, will oversee the buddy system. Responsibilities: Collect all buddy-checked papers after class. Record for each student: Buddy’s name who checked the paper. Number of checks received (0, 1, or 2). Ensure all buddy system procedures are followed (underlines and check marks). Submit a tally sheet to the professor by 6 PM of class day. Important: The monitor does not grade anything. Failure to follow these steps may affect participation points for the monitor or the class. Expectations: Both checks must be present to receive full participation credit. No shortcuts; discussion must reflect understanding. 3.2 Problem Sets (1 and 2) Topic Assignment and Scope Topics and scope for Problem Sets 1 and 2 will be assigned randomly on the first day of class. Assignment will be done by drawing from prepared topic papers. Assigned topics are final and will be finalized by Week 2. Students may not change, narrow, or expand their assigned scope without instructor approval. If two groups converge on substantively similar topics or datasets, both submissions will be penalized. Format: Hard copy submission only, with handwritten discussion. R code can be typed and printed for submission. Graphics must be printed and pasted into the submission. Guidelines: Problem Sets 1 &amp; 2 questions are provided in the LBOMETR Course Book on the first day of class. Each problem must include: Discussion: Handwritten explanation of the solution. R Script: Step-by-step, well-commented, reproducible code. Graphics: Printed plots, properly labeled. Submission deadlines: PS1: Week 6 (covers material until Descriptive Statistics). PS2: Week 12 (covers material from Descriptive Statistics to Formal Tests of Assumptions). Expectations: Students must demonstrate understanding of economic theory and econometric reasoning in discussion. The same groupings apply in all group-related outputs. Only essential outputs should be included; do not submit unnecessary or repetitive results. Problem Set Rubric (Group Graded) Criteria Exemplary (90–100) Satisfactory (78–89) Developing (72–77) Beginning (&lt;72) Weight Data Cleaning &amp; Preparation Data is fully imported, cleaned, and transformed. Missing values, inconsistencies, and errors are handled effectively. Decisions are logical and appropriate for messy datasets. Mostly clean; minor errors or inconsistencies remain. Basic understanding of cleaning demonstrated. Partially cleaned; several errors remain. Some steps missing or unclear. Data largely unclean or incorrectly processed. Minimal understanding of preparation. 25 Coding &amp; Step-by-Step Process Code is correct, reproducible, well-organized, and clearly commented. Workflow is logical and easy to follow. Mostly correct; minor errors or inefficiencies. Workflow mostly clear. Code partially correct or poorly organized. Workflow unclear or incomplete. Code largely incorrect, not reproducible, or disorganized. Workflow missing. 30 Analysis &amp; Interpretation (Discussion) Answers are complete, insightful, and clearly interpret results in context. Discussion shows critical thinking. Answers mostly correct; interpretation present but limited. Some insights missing. Answers partially correct; interpretation weak or incomplete. Answers incorrect or missing; interpretation absent. 25 Graphics &amp; Visualization Visuals are clear, professional, and effectively support the discussion. Correctly printed and pasted. Visuals mostly clear and relevant; minor issues. Basic or unclear visuals; limited relevance. Missing, incorrect, or irrelevant visuals. 10 Presentation &amp; Documentation Submission is neat, organized, and easy to follow. Typed code separated from handwritten discussion. All required components included. Submission mostly organized; minor issues in clarity or order. Submission somewhat disorganized; some components missing or hard to follow. Submission poorly organized, incomplete, or difficult to follow. 10 Total 100 points (group) 3.3 Data Storytelling Format: Live in-person presentation, slides submitted electronically. Mock Presentation Slides submitted via email at 21:00 a day before the mock presentation. Final Presentation Slides submitted as a link via email at 21:00 a day before the scheduled presentation. Guidelines: Presentation duration: 10 minutes, followed by 5-minute Q&amp;A. Structure: Introduction: Topic, research question, significance Methods: Data and analysis methodology Results: Key findings using R-generated visualizations Discussion &amp; Conclusion: Implications and actionable recommendations Each group member must actively participate, meaning, speak during the presentation. No cue cards or reading from their laptops, or cellphones; presenters must be familiar with their slides. Slides must reflect economic reasoning and econometric reasoning. Room to be used will be reserved for both online and in-person audiences. Feedback will be given during the Data Storytelling and must be considered when making the Data Story Archive. Data Storytelling Rubric (Individually Graded) Criteria Exemplary Satisfactory Developing Beginning Weight Content &amp; Narrative Quality Student clearly owns a specific section. Introduction, methods, and results are clear, concise, logically presented, and analytically interpreted. Conclusions or implications are insightful and actionable. Section is clear and correct but mostly descriptive. Interpretation is present but limited. Conclusions are solid but not fully actionable. Section is vague, rushed, or weakly connected. Interpretation is superficial. Conclusions are simplistic or partially missing. Section is unclear, disorganized, or incorrect. Major parts of discussion or conclusions are missing. 40 Visualizations &amp; Analytical Support Student demonstrates clear ownership of visuals or analytical elements. Visuals are professional, polished, and strongly support the story. Any dynamic elements are used effectively. Visuals are appropriate and support the analysis, but design or relevance could be improved. Minor flaws or missed opportunities. Visuals are basic, poorly designed, or loosely connected. Some key visual aids missing. Visuals are missing, irrelevant, or poorly designed. 30 Delivery, Engagement &amp; Individual Contribution Student presents confidently, speaks naturally, and clearly explains their section. Demonstrates preparation and understanding. Contribution is observable in the presentation itself. Delivery is generally clear. Student shows understanding but occasionally relies on notes. Contribution is evident but not fully developed. Delivery is hesitant or partially scripted. Understanding of section is weak. Contribution is unclear. Delivery is minimal or absent. Student cannot demonstrate understanding of their section. 30 Total 100 points (individual) 3.4 Data Story Archive Format: Single hard copy PDF submission for the instructor. Content Requirements: Cover Page: Title, group members, submission date. Table of Contents: Clear page references. Data Story Report: Maximum 12 pages. Introduction: Problem statement and research question. Methods: Data sources, methodology, analysis techniques. Results: Key findings with R-generated visuals. Discussion &amp; Conclusion: Implications and recommendations. References: Expected to have more than 10 references; APA format Appendix: Maximum 5 pages, supporting tables or plots only. R Scripts: Maximum 10 pages, rendered from Quarto Markdown. Must include data cleaning steps, outputs, and plots. Group Reflection: Strictly 2 pages. Discuss teamwork, learning outcomes, and growth in data analysis during the whole duration of the course. Submission Instructions: Deadline: 18:00 TUESDAY OF WEEK 14 Expectations: Archive must reflect independent group work. No generative AI or external assistance in final output. Data Story Archive Rubric (Group Graded) Criteria Exemplary Satisfactory Developing Beginning Weight Content &amp; Storytelling (Report) Report is clear, concise, logically structured, and fully explains the analysis. Results are interpreted correctly, insights are highlighted, and conclusions are actionable. No irrelevant or redundant material included. Report is generally clear and correct but may be somewhat descriptive or slightly unorganized. Interpretation of results is present but not fully analytical. Report has gaps in clarity, logic, or completeness. Results are mostly descriptive. Conclusions are weak or partially missing. Report is unclear, incomplete, or disorganized. Major parts of analysis, results, or conclusions are missing or incorrect. 40 Technical Work (Code &amp; Analysis) Code is correct, fully reproducible, neat, well-commented, and logically structured. Step-by-step workflow is clear. Only relevant outputs are shown; no unnecessary tables or raw dumps. Code is mostly correct and reproducible, but minor inefficiencies, clutter, or documentation gaps exist. Some irrelevant outputs may be present. Code runs but has errors, poor structure, weak documentation, or unclear workflow. Outputs may be excessive or partly irrelevant. Code is largely incorrect, incomplete, not reproducible, or disorganized. Outputs are missing or meaningless. 45 Presentation &amp; Organization (Archive) Archive is professional, well-organized, and easy to navigate. Report and code are clearly separated. File naming and readability are consistent and logical. Archive is generally organized but may have minor inconsistencies or minor clutter. Separation of report and code is acceptable. Archive is somewhat confusing or inconsistent. Report and code separation is unclear. Archive is poorly organized, confusing, or incomplete. Report and code are difficult to access or understand. 15 Total 100 points (group) 3.5 Participation Buddy System Form: Attendance &amp; Engagement and Buddy System Participation will be monitored and checked through the Buddy System Evaluation Form. Individual Evaluation Form: Each student must also complete a Group Work Evaluation Form assessing group mates . The form must be signed to certify accuracy and truthfulness. Submission Requirements: Submit the signed evaluation forms alongside your Data Story Archive Report. Grading Notes: Attendance &amp; Engagement: Tracked via buddy form (presence in class/workshop, active participation). Buddy System Participation: Accuracy of buddy checks, initials, and verification. Group Work Contribution: Quality, quantity, and timeliness of contributions to problem sets and presentations. Collaboration &amp; Communication: Professional, constructive, and coordinated communication within the group. Participation Rubric (Individually Graded) Criteria Exemplary (90–100) Satisfactory (78–89) Developing (72–77) Beginning (&lt;72) Weight Attendance &amp; Engagement Attends all meetings/classes and actively participates in discussions, activities, and workshops. Demonstrates initiative and preparedness. Attends most meetings/classes (≥80%) and participates adequately. Minor lapses in engagement. Attends some meetings/classes (≥60%) or participates inconsistently. Minimal contribution in discussions. Frequently absent (&lt;60%) or disengaged. Rarely participates. 25% Buddy System Participation Always performs buddy responsibilities accurately: checks seatmate’s discussion, underlines components, initials verification, ensures accountability. Usually performs buddy responsibilities correctly; occasional minor lapses. Sometimes performs buddy responsibilities; inconsistencies in marking or verifying. Rarely or never performs buddy responsibilities; no accountability. 20% Group Work Contribution Actively contributes to group activities (problem sets, data storytelling). Attends meetings, shares workload equitably, helps group succeed. Participates in group activities most of the time. Completes assigned tasks with minor support needed. Limited participation in group activities. Contributes only partially to assigned tasks. Minimal or no participation in group activities. Does not contribute to group tasks. 30% Collaboration &amp; Communication Communicates effectively and professionally within the group. Supports peers, resolves conflicts constructively, and helps coordinate tasks. Communicates adequately within the group. Minor issues in coordination or collaboration. Communication within the group is inconsistent; conflicts or coordination issues sometimes occur. Poor or absent communication. Causes confusion or conflict in group. 25% Total 100 points 3.6 Grading System Data Storytelling 25% Data Story Archive 35% Problem Sets (2) 15% Short Quizzes 15% Class Participation 10% Total 100% 3.7 Grading Scale 97.00 - 100.00 4.0 90.00 – 96.99 3.5 85.00 – 89.99 3.0 80.00 – 84.99 2.5 75.00 – 79.99 2.0 70.00 – 74.99 1.5 65.00 – 69.99 1.0 00.00 – 64.99 0.0 Note: For course credit, students should get a minimum score of 65.00% (equivalent to a grade of 1.0) "],["problem-sets.html", "4 Problem Sets 4.1 Introduction 4.2 Assigned Topics List (General and Specific) 4.3 Problem Set 1 - Data Management to Descriptive Statistics and Conceptual Endogeneity 4.4 Problem Set 2 - Testable Hypotheses, OLS, Diagnostics, Robustness 4.5 Reminders:", " 4 Problem Sets 4.1 Introduction You are a team assigned to conduct research on one of the following topics. Each group will receive a specific topic randomly from the list below. Your tasks are divided into two Problem Sets: Problem Set 1: Data Management Visualization Descriptive Statistics Conceptual Endogeneity Problem Set 2 Formulate Testable Hypotheses OLS Estimation Diagnostics Sensitivity/Robustness Checks Important: All datasets must come from PSA OpenSTAT or World Bank Open Data. If you want to use other datasets, you must inform the lecturer by Week 2. No Kaggle or any cleaned datasets allowed. 4.2 Assigned Topics List (General and Specific) Trade and Economic Outcomes a. Export volume and regional economic growth b. Imports, domestic production, and household income c. Trade openness and employment in key sectors Agriculture and Productivity a. Crop yield differences by farm size b. Fertilizer input and productivity c. Regional specialization in agriculture Money, Banking and Household Finance a. Household access to banking and income b. Regional credit availability and small business activity c. Income, savings, and household financial stability Stocks and Capital Markets a. Stock market index movements and GDP b. Stock volatility and investment or savings c. Economic shocks and market performance Education and Human Capital a. Educational attainment and earnings b. Regional schooling differences and income disparities c. Education spending and enrollment/completion rates Health and Economic Outcomes a. Health expenditure and labor productivity b. Regional health access and income c. Health outcomes and employment 4.3 Problem Set 1 - Data Management to Descriptive Statistics and Conceptual Endogeneity Deadline: Week 6 Note: HW means handwritten. Data Management and Cleaning Acquire dataset(s) for your assigned topic Clean data (handle missing values, recode variables, reshape, etc.) Report observations before and after cleaning (HW) Data Visualization Create at least 3 visualizations For each visualization: Explain why you chose it (HW) Discuss what it shows in economic terms (HW) Interpret patterns, trends, or anomalies (HW) Descriptive Statistics Compute summary statistics (mean, median, SD) Compare across groups, regions, or categories Discuss findings in economic terms (HW) Conceptual Endogeneity / Confounding Variables Identify at least one variable that might confound relationships (HW) Discuss how it could bias interpretation (HW) Economic Discussion Summarize your findings clearly (HW) Link patterns to economic reasoning or policy (HW) 4.4 Problem Set 2 - Testable Hypotheses, OLS, Diagnostics, Robustness Deadline: Week 12 Note: HW means handwritten. Formulate Testable Hypotheses Clearly define dependent and independent variables OLS Estimation Run bivariate OLS Run multivariate OLS with controls Report coefficients, standard errors, and R2 (Note: This can be printed and pasted) Discuss (HW): Economic interpretation of coefficients Can the OLS be interpreted causally? Why or why not? Potential sources of bias Sensitivity/ Robustness Checks Test whether results hold with different sets of control variables Perform subsample analysis (i.e., gender, region, time period) Discuss which results are robust, which change and why (HW) Please emphasize your discussion with economic interpretation (HW) Diagnostics or Formal Tests Multicollinearity (VIF) Heteroskedasticity (BP or White) Functional form (RESET) Discuss the implications of the results (HW) Economic Discussion (HW) Compare bivariate vs multivariate results and the sensitivity checks Summarize findings with Problem Set 1, policy, limitations 4.5 Reminders: Hard copy submission is the only submission accepted. All with (HW) means these are handwritten. Please write legibly. Typed R code printed and included. Plots are printed and pasted together with the handwritten discussion. Only include essential outputs meaning, no need to print the dataset contents, whatsoever. First pages would be the answers to all questions together then, next pages would be the step-by-step process with code chunks in R. In printing the Quarto Markdown file for submission, put in the code chunks the following line on top where you see the {r}. It should be like this: {r, eval=FALSE}. This is so that the results will not appear in the HTML. You can then print the Quarto Markdown clearly. Only do this when you are printing the R codes. "],["basic-introduction-to-r.html", "5 Basic Introduction to R 5.1 Session Information 5.2 Preliminaries 5.3 Packages 5.4 Setting up the Working Directory 5.5 Cleaning the Environment (Do This Regularly) 5.6 Quarto Markdown 5.7 Working Directories and File Management 5.8 Mini-Exercise: First Quarto Render (Mandatory per Individual)", " 5 Basic Introduction to R This portion of the book offers an introduction to the basics of R. R offers a wide variety of functionality. Note that this book only offers basic Econometric analysis. It will be useful to have some basic familiarity with R and its syntax but this is not strictly necessary. Each chapter includes both R code and results to make it easier for students to follow along, even without detailed knowledge of R. 5.1 Session Information This version of the book was built using R version 4.4.2. See below for the session information: ## R version 4.5.2 (2025-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 ## Running under: Windows 11 x64 (build 26200) ## ## Matrix products: default ## LAPACK version 3.12.1 ## ## locale: ## [1] LC_COLLATE=English_Netherlands.utf8 LC_CTYPE=English_Netherlands.utf8 ## [3] LC_MONETARY=English_Netherlands.utf8 LC_NUMERIC=C ## [5] LC_TIME=English_Netherlands.utf8 ## ## time zone: Asia/Manila ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] lubridate_1.9.4 forcats_1.0.1 stringr_1.6.0 dplyr_1.1.4 purrr_1.2.0 ## [6] readr_2.1.6 tidyr_1.3.2 tibble_3.3.0 ggplot2_4.0.1 tidyverse_2.0.0 ## [11] readxl_1.4.5 ## ## loaded via a namespace (and not attached): ## [1] jsonlite_2.0.0 gtable_0.3.6 crayon_1.5.3 compiler_4.5.2 ## [5] tidyselect_1.2.1 jquerylib_0.1.4 scales_1.4.0 yaml_2.3.12 ## [9] fastmap_1.2.0 R6_2.6.1 labeling_0.4.3 generics_0.1.4 ## [13] knitr_1.51 bookdown_0.46 bslib_0.9.0 pillar_1.11.1 ## [17] RColorBrewer_1.1-3 tzdb_0.5.0 rlang_1.1.6 cachem_1.1.0 ## [21] stringi_1.8.7 xfun_0.55 sass_0.4.10 S7_0.2.1 ## [25] timechange_0.3.0 cli_3.6.5 withr_3.0.2 magrittr_2.0.4 ## [29] digest_0.6.39 grid_4.5.2 rstudioapi_0.17.1 hms_1.1.4 ## [33] lifecycle_1.0.4 vctrs_0.6.5 evaluate_1.0.5 glue_1.8.0 ## [37] farver_2.1.2 cellranger_1.1.0 rmarkdown_2.30 tools_4.5.2 ## [41] pkgconfig_2.0.3 htmltools_0.5.9 5.2 Preliminaries The first step is to gain access to R, which is free and available on the R website: http://cran.r-project.org/. Simply go to the R website, select the appropriate location and operating system, and follow the instructions to download the base distribution of R. RStudio offers a user friendly environment to run R and is recommended. Once R is opened, we can begin to run commands. R commands can be run directly from the console, from the R script editor or from a text editor separate from R. 5.2.1 Understanding the RStudio Screen Console (Bottom Left) This is where you see the output from your code Error messages Warnings You can type R commands directly in the console after the &gt; and press Enter to run them. Try it! Type 3*9 Use the console for: Quick calculations Testing commands Seeing results Important! Anything types only in the console is not saved. Script/Editor Area (Top Left) The Script area is where you write and save your code or Quarto documents. This is where R scripts and qmd files are written. Code here is saved, reproducible, and reusable. To run code from the script: Select a line and press Ctrl+Enter (Windows) or Cmd+Enter (Mac) or just place the cursor beside the line to run it. Run a whole chunk in Quarto Rule: Always write code in the script/editor, not in the console. Environment (Top Right) The Environment shows all objects currently in memory such as data frames, variables, functions, models. Try this: type jmn&lt;-1101 in the console. After running this, jmn will appear in the Environment. If something does NOT appear, it does not exist in your session. Files, Plots, Packages, Help, Viewer (Bottom Right) This panel has multiple tabs: Files Shows files in your working directory. Your working directory can be seen just below the Console, the one after ~ Use this to navigate project files Plots Displays graphs created by code Packages Shows list of installed packages. Checkboxes allow loading/unloading packages but you still need to add in the code library() in scripts for reproducibility. Help Displays help pages Viewer Shows rendered HTML outputs Used when previewing Quarto documents R offers detailed help files for each function. To access help, run: ?sum All lines proceeded by a # are comments and will not run*. For example: # This is a comment. R will not recognize this as a command. 5.3 Packages Each package of interest must be installed and loaded before it can be used. The packages will not be immediately available when R is opened. A package only has to be installed once on a computer, but the package will have to be loaded every time R is restarted. We can install a package individually as we need them. For example, to install tidyverse and psych, we would do: install.packages(&quot;tidyverse&quot;) install.packages(&quot;psych&quot;) In the tidyverse package, the ggplot2 is usually included; if you do not see the package in the Packages list at the lower right, you can do this: if(!(&quot;ggplot2&quot; %in% installed.packages()[,&quot;Package&quot;])) install.packages(&quot;ggplot2&quot;) Now that we have our packages successfully installed, we can go ahead and load them into R. Here we will load the tidyverse package as an example. We can use of all the functions available in that package once it is loaded into R. We load packages by using a library() function. The input is the name of the package, not in quotes. library(tidyverse) We can look up all of the functions within a package by using a help() function. For example, let’s look at the functions available in the tidyverse package. help(package = tidyverse) Note that the package argument is necessary to look up all of the functions. We can also detach a package if we no longer want it loaded. This is sometimes useful if two packages do not play well together. Here we will use a detach() function. detach(package:tidyverse) For simplicity, we will assume that the reader has restarted R at the beginning of each tutorial. 5.4 Setting up the Working Directory MOST IMPORTANT! If your working directory is incorrect, R will not find your files and your code will fail even if it is correct. 5.4.1 What is a Working Directory? The working directory is the folder where R looks for data files, saves outputs, where .qmd files should be placed. You will only use one main local folder as your working directory (technically two: one in your laptop, one in your university account computer) 5.4.2 Required Folder Structure Create a folder: DLSU_COURSE_SECTION This folder is your local working directory. On university computers: create this folder inside your university account storage. On your personal computer: create this folder anywhere convenient for you. All qmd files must be placed inside this folder! 5.4.3 Setting the Working Directory in RStudio This method works on both Windows and Mac and avoids typing errors. Open RStudio Go to Session&gt;Set Working Directory&gt;Choose Working Directory Select the folder DLSU_COURSE_Section Click Open Once set, R will treat this folder as the default location for all files; meaning, all files in the course should be placed in this folder. Download files then place in this folder. 5.4.4 Setting the Working Directory Using Code This is a hassle as you will manually code working directory using setwd() Windows: # Use double backslashes \\\\ or forward slashes / setwd(&quot;C:\\\\Users\\\\YourUsername\\\\Documents\\\\DLSU_COURSE_Section&quot;) setwd(&quot;C:/Users/YourUsername/Documents/DLSU_COURSE_Section&quot;) Mac: # Use forward slashes / setwd(&quot;/Users/YourUsername/Documents/DLSU_LBOMETR_Section&quot;) How to get the path? I forgot! Just kidding. I just right-click on the file and copy as path name. I am not sure how it is with Mac, I think same, right click but press option so the path name will show up. To confirm your working directory: getwd() If the printed path is NOT DLSU_COURSE_Section, fix it. 5.5 Cleaning the Environment (Do This Regularly) You should clean your environment at the start of a new lecture, when switching datasets, or when something behaves unexpectedly. # Remove all objects from the environment rm(list = ls()) # Free up memory (makes processor faster) gc() The Environment panel should be empty. You are always starting with a clean session. 5.6 Quarto Markdown In this course, Quarto Markdown (.qmd files). Quarto Markdown is a tool for creating documents, reports and presentations using Markdown and executable code. 5.6.1 Installing Quarto in R Before starting, install the quarto R package if not already installed: install.packages(&quot;quarto&quot;) 5.6.2 Starting a Quarto Document To begin creating a Quarto document, follow these steps: Open RStudio. Go to File &gt; New File &gt; Quarto Document. Choose the document type (e.g., HTML, PDF, Word, etc.) and specify whether the document will include code. For ease, we will use the html document type. Use the visual editor for ease of editing. 5.6.3 YAML Header Use Here is the YAML header for all quarto documents that you will submit along with line-by-line explanations. title: “TITLE of the FILE” This contains the title of the document. It appears at the top and in the browser tab. author: “put your name here” Replace with your name. Identifies the document author. date: today Automatically inserts the current date. format: html: toc: true theme: united embed-resources: true Format specifies the output type (html in this case), adds a table of contents, sets a bootstrap html theme (you can use other themes but this is preferred), embeds all resources in the html file. knitr: opts_chunk: warning: false message: false Controls code chunk behavior, meaning, it hides warnings and hides messages when rendering. editor: visual Uses the visual editor in Rstudio for the output Marks the end of the YAML header. As a whole, the YAML header looks like this: 5.6.4 Quarto Key Features Code Chunks Code chunks allow you to include and run code inside your document. To make code chunks, long way (there is shortcut later). Type ```{r} then press Enter. If you want to run the specific code chunk, you can also press the green play button at the right side of the chunk. If you want to run previous code chunks, press the button that has an arrow down with a green line below, just beside the green play button. jem&lt;-15+50+143 Inline Code Embed R code in text using backticks and r . Try typing this: The total number of pairs is “r 15+12”. Replace the quotation marks with backticks. When you render the file, what should come out in place of the backticks thing would be the number 27. 5.6.5 Quarto Markdown Shortcuts Action Windows Shortcut Mac Shortcut Insert a new code chunk Ctrl+Alt+I Cmd+Option+I Run current code chunk Ctrl+Shift+Enter Cmd+Shift+Enter Run all code chunks Ctrl+Alt+R Cmd+Alt+R Run current line/selection Ctrl+Enter Cmd+Enter Knit/Render document Ctrl+Shift+K Cmd+Shift+K Comment/uncomment lines Ctrl+Shift+C Cmd+Shift+C Insert pipe (%&gt;%) Ctrl+Shift+M Cmd+Shift+M Headings /H Number of Heading (if in Visual mode) Prefix line with #, ##, etc. manually (in Source mode) /H Number of Heading (if in Visual mode) Prefix line with #, ##, etc. manually (in Source mode) Bold Ctrl+B Cmd+B Italic Ctrl+I Cmd+I Inline code Surround with backticks (’) manually Surround with backticks (’) manually 5.6.6 Rendering a Quarto Document Rendering is the process of turning your .qmd file into an html. No rendering done, no submission. In this course, you will primarily render to HTML. 5.6.6.1 Render Using RStudio Button (DO THIS) Open your qmd file Make sure it is saved in the working directory Click Render button at the top of the editor. It looks like a blue arrow with the word Render. RStudio will run all code chunks, convert the document to HTML then open the result in the Viewer pane. If the render is successful, an html file will appear in your Files tab. You can double-click on the html file in your Files so that it appears in a bigger window which you can use to print as PDF. 5.7 Working Directories and File Management You will always work locally first. Each student must: Edit .qmd files only inside their local DLSU_COURSE_Section folder. Render HTML files locally to check for errors Never edit files directly inside Google Drive via a browser 5.7.1 File Naming Convention (Mandatory) To avoid confusion, all .qmd files must follow this format: initials_topic.qmd Example: jmn_descriptives.qmd jmn_visualization.qmd/ 5.8 Mini-Exercise: First Quarto Render (Mandatory per Individual) This exercise checks that you can write, run, and render a Quarto document correctly. Instructions: Create a new Quarto HTML document in RStudio. Keep the YAML header exactly as shown earlier in this chapter. In the body of the document, do the following steps: a. Add a Section Header Below the YAML header, add the following Markdown header: About Me as Heading 1 Under this header, write 2-3 sentences introducing yourself (name, program, year, hobbies) b. Add Inline Code for your age In the same section, add a sentence that includes inline R code. Sentence: I am “r 2026-type your year of birth” years old. Do NOT calculate your age manually. The age must be computed by R. The number should appear as plain text in the sentence. c. Add a Code Chunk Insert a new R code chunk. Inside the chunk: Add a comment saying this is just a test Create an object named after your initials Add the alphabetical positions of your initials Print the result Example: #This is just a test jmn&lt;-10+13+14 print(jmn) ## [1] 37 d. Render the document This exercise will help you in future lectures! e. Create a new Quarto document Clean the environment and free up the memory. Don’t forget your YAML header before the code chunk including the cleaning and freeing the memory! "],["data-management---cross-sectional-data.html", "6 Data Management - Cross-Sectional Data 6.1 Where to Get Data? 6.2 Preliminaries 6.3 Data Cleaning 6.4 Closing", " 6 Data Management - Cross-Sectional Data 6.1 Where to Get Data? Before we proceed to Data Management, let us first find where we can get data for the Data Story Archive. Note that the data you collect should still ensure that you are following the Code of Ethics and analyze Ethical Considerations. Please view the necessary documents from the Office of the Vice Chancellor for Research and Innovation (https://www.dlsu.edu.ph/research/research-manual/) A list of links you can search and get data from: Note: I will not include the best links as they are pretty straightforward and these are governmental databases like the ones from World Bank, IMF, UN, Philippine Statistics Authority, and Bangko Sentral ng Pilipinas. The list here is a general list but use with proper discretion. Name Link Notes Awesome Public Datasets https://github.com/awesomedata/awesome-public-datasets This repository is filled with public datasets, mostly from International contexts. Google Dataset Search https://datasetsearch.research.google.com/ You can download publicly available datasets from searching through Google. Though, sometimes the datasets come from ‘Statista.com’. You can check the sources from the search. 6.2 Preliminaries 6.2.1 Packages We will mostly use the tidyverse package, in particular, the dplyr package and the tidyr package; double-check in your Packages list whether you have these two packages; if not, you can simply install them. 6.2.2 Clean Everything Do this step every time you use other data or when we do the other chapters. # Remove all objects in the global environment rm(list = ls()) # Perform garbage collection to free up memory gc() ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 2957606 158.0 5811240 310.4 3746138 200.1 ## Vcells 6358005 48.6 12255594 93.6 10143179 77.4 6.2.3 Importing the Datasets Before we can manage the data, we must first import it into R. There are two ways to do this: Writing code (preferred for replicability) Clicking in RStudio We start with the most common file types. 6.2.3.1 Importing a CSV file cp_csv&lt;-read.csv(&quot;CP_1.csv&quot;) The file must be in the working directory. If it is not, then, simply putting the file name inside the quotation marks will not work. Meaning, you have to input the entire path where the file is. Another, if you notice, the CSV file name is simple and easy to share. The object, in this case, cp_csv is also in small letters and does not have spaces but rather an underscore replacing the space. Always do this when naming objects. a. Small letters b. No spaces c. Place underscore instead. To check the information and what the dataset looks like: head(cp_csv) ## Country ID HH1_Num_People HH2a_Sex HH2b_Age ## 1 Bulgaria BG1535216 3 Female 56 ## 2 Netherlands NL5130211 1 Female 20 ## 3 Netherlands NL5063519 2 Male 63 ## 4 Slovenia SI1042916 3 Male 63 ## 5 Bulgaria BG1396625 2 Male 89 ## 6 Slovakia SK1184115 2 Female 44 ## HH2d_EmploymentSituation Q1_PaidJob ## 1 Unemployed less than 12 months Yes ## 2 In education (at school, university, etc.) / student Yes ## 3 Retired Yes ## 4 At work as employee or employer/self-employed &lt;NA&gt; ## 5 Retired Yes ## 6 At work as employee or employer/self-employed &lt;NA&gt; ## Q2_Empoyment Q3_Contract ## 1 &lt;NA&gt; &lt;NA&gt; ## 2 &lt;NA&gt; &lt;NA&gt; ## 3 &lt;NA&gt; &lt;NA&gt; ## 4 Employed On an unlimited permanent contract ## 5 &lt;NA&gt; &lt;NA&gt; ## 6 Self-employed without employees On an unlimited permanent contract ## Q4_Occupation Q7_HoursWeekWork Q7a_AdditionalJob Q7b_HoursWeekWeekAddJob ## 1 &lt;NA&gt; NA &lt;NA&gt; NA ## 2 &lt;NA&gt; NA &lt;NA&gt; NA ## 3 &lt;NA&gt; NA &lt;NA&gt; NA ## 4 Technician or junior professional 35 No NA ## 5 &lt;NA&gt; NA &lt;NA&gt; NA ## 6 Technician or junior professional 43 No NA ## Q7c_Work Q8_HoursWeekWorkPref Q9_HoursWeekWorkPartner Q10_HoursWeekWorkPartnerPref Q17_Rooms ## 1 No 40 40 4 3 ## 2 No 10 NA NA 1 ## 3 No 0 NA 0 6 ## 4 &lt;NA&gt; 30 NA 30 3 ## 5 No 0 NA 0 1 ## 6 &lt;NA&gt; 43 NA NA 2 ## Q18_Tenancy Q19a_ShortageSpace Q19b_Rot Q19c_Leaks ## 1 Own without mortgage 0 0 0 ## 2 Other 0 0 0 ## 3 Own with mortgage 0 0 0 ## 4 Tenant, paying rent to private landlord 0 0 0 ## 5 Own without mortgage 0 0 0 ## 6 Own without mortgage 1 0 0 ## Q19d_NoFlusingToilet Q19e_NoBathShower Q19f_NoOutside Q20_LeaveAccomodation_NoAff ## 1 0 0 0 Very unlikely ## 2 0 0 0 Quite unlikely ## 3 0 0 0 Very unlikely ## 4 0 0 0 Quite unlikely ## 5 0 0 0 Very unlikely ## 6 0 0 0 Very likely ## Q24_Trust Q25a_TensionClass Q25b_TensionWork Q25c_TensionSex ## 1 6 Some tension No tension No tension ## 2 6 Some tension Some tension No tension ## 3 8 Some tension Some tension No tension ## 4 6 Some tension Some tension No tension ## 5 1 - you can&#39;t be too careful Some tension Don”t know Some tension ## 6 5 Some tension Some tension Some tension ## Q25d_TensionsAge Q25e_TensionRace Q25f_TensionReligion Q25g_TensionSexOrient ## 1 3 Some tension No tension No tension ## 2 3 Some tension Some tension A lot of tension ## 3 3 A lot of tension A lot of tension Some tension ## 4 3 Some tension Some tension No tension ## 5 2 Don”t know Don”t know Don”t know ## 6 2 Some tension Some tension Some tension ## Q37a_HoursWeekChildren Q37b_HoursWeekHousework Q37c_HoursWeekElderly Q48_Education ## 1 2 14 NA 1250 ## 2 NA 7 NA 2956 ## 3 NA 14 3 2963 ## 4 5 NA NA 3420 ## 5 NA NA NA 1253 ## 6 NA 20 NA 3530 ## Q49_Area Q50a_NeighbourhoodNoise Q50b_NeighbourhoodAir Q50c_NeighbourhoodWater ## 1 A medium to large town No problems No problems Major problems ## 2 A city or city suburb No problems No problems No problems ## 3 A medium to large town No problems No problems No problems ## 4 A medium to large town No problems No problems No problems ## 5 A city or city suburb No problems No problems No problems ## 6 A medium to large town No problems No problems No problems ## Q50d_NeighbourhoodCrime Q50e_NeighbourhoodLitter Q50f_NeighbourhoodTraffic ## 1 No problems No problems No problems ## 2 No problems No problems No problems ## 3 No problems No problems No problems ## 4 No problems No problems Moderate problems ## 5 Moderate problems Moderate problems Don&#39;t know ## 6 No problems No problems Moderate problems ## Q51a_AccServicesPost Q51b_AccServicesBank Q53c_QualityPublicTransport Income_PPP ## 1 Service not used Easily 6 NA ## 2 Easily With some difficulty 7 273.4731 ## 3 Easily Easily 7 3190.5196 ## 4 Easily Easily 6 4171.6329 ## 5 Service not used Service not used 3 478.3407 ## 6 Very easily Very easily 5 759.6961 str(cp_csv) ## &#39;data.frame&#39;: 4036 obs. of 49 variables: ## $ Country : chr &quot;Bulgaria&quot; &quot;Netherlands&quot; &quot;Netherlands&quot; &quot;Slovenia&quot; ... ## $ ID : chr &quot;BG1535216&quot; &quot;NL5130211&quot; &quot;NL5063519&quot; &quot;SI1042916&quot; ... ## $ HH1_Num_People : int 3 1 2 3 2 2 2 1 4 2 ... ## $ HH2a_Sex : chr &quot;Female&quot; &quot;Female&quot; &quot;Male&quot; &quot;Male&quot; ... ## $ HH2b_Age : int 56 20 63 63 89 44 52 43 47 81 ... ## $ HH2d_EmploymentSituation : chr &quot;Unemployed less than 12 months&quot; &quot;In education (at school, university, etc.) / student&quot; &quot;Retired&quot; &quot;At work as employee or employer/self-employed&quot; ... ## $ Q1_PaidJob : chr &quot;Yes&quot; &quot;Yes&quot; &quot;Yes&quot; NA ... ## $ Q2_Empoyment : chr NA NA NA &quot;Employed&quot; ... ## $ Q3_Contract : chr NA NA NA &quot;On an unlimited permanent contract&quot; ... ## $ Q4_Occupation : chr NA NA NA &quot;Technician or junior professional&quot; ... ## $ Q7_HoursWeekWork : int NA NA NA 35 NA 43 NA NA 17 NA ... ## $ Q7a_AdditionalJob : chr NA NA NA &quot;No&quot; ... ## $ Q7b_HoursWeekWeekAddJob : int NA NA NA NA NA NA NA NA NA NA ... ## $ Q7c_Work : chr &quot;No&quot; &quot;No&quot; &quot;No&quot; NA ... ## $ Q8_HoursWeekWorkPref : int 40 10 0 30 0 43 40 40 35 0 ... ## $ Q9_HoursWeekWorkPartner : int 40 NA NA NA NA NA 41 NA 35 NA ... ## $ Q10_HoursWeekWorkPartnerPref: int 4 NA 0 30 0 NA 30 NA 35 0 ... ## $ Q17_Rooms : int 3 1 6 3 1 2 NA 1 5 3 ... ## $ Q18_Tenancy : chr &quot;Own without mortgage&quot; &quot;Other&quot; &quot;Own with mortgage&quot; &quot;Tenant, paying rent to private landlord&quot; ... ## $ Q19a_ShortageSpace : int 0 0 0 0 0 1 0 0 0 0 ... ## $ Q19b_Rot : int 0 0 0 0 0 0 0 1 1 0 ... ## $ Q19c_Leaks : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Q19d_NoFlusingToilet : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Q19e_NoBathShower : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Q19f_NoOutside : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Q20_LeaveAccomodation_NoAff : chr &quot;Very unlikely&quot; &quot;Quite unlikely&quot; &quot;Very unlikely&quot; &quot;Quite unlikely&quot; ... ## $ Q24_Trust : chr &quot;6&quot; &quot;6&quot; &quot;8&quot; &quot;6&quot; ... ## $ Q25a_TensionClass : chr &quot;Some tension&quot; &quot;Some tension&quot; &quot;Some tension&quot; &quot;Some tension&quot; ... ## $ Q25b_TensionWork : chr &quot;No tension&quot; &quot;Some tension&quot; &quot;Some tension&quot; &quot;Some tension&quot; ... ## $ Q25c_TensionSex : chr &quot;No tension&quot; &quot;No tension&quot; &quot;No tension&quot; &quot;No tension&quot; ... ## $ Q25d_TensionsAge : int 3 3 3 3 2 2 98 3 3 1 ... ## $ Q25e_TensionRace : chr &quot;Some tension&quot; &quot;Some tension&quot; &quot;A lot of tension&quot; &quot;Some tension&quot; ... ## $ Q25f_TensionReligion : chr &quot;No tension&quot; &quot;Some tension&quot; &quot;A lot of tension&quot; &quot;Some tension&quot; ... ## $ Q25g_TensionSexOrient : chr &quot;No tension&quot; &quot;A lot of tension&quot; &quot;Some tension&quot; &quot;No tension&quot; ... ## $ Q37a_HoursWeekChildren : int 2 NA NA 5 NA NA 4 NA NA NA ... ## $ Q37b_HoursWeekHousework : int 14 7 14 NA NA 20 4 8 4 6 ... ## $ Q37c_HoursWeekElderly : int NA NA 3 NA NA NA NA NA NA NA ... ## $ Q48_Education : chr &quot;1250&quot; &quot;2956&quot; &quot;2963&quot; &quot;3420&quot; ... ## $ Q49_Area : chr &quot;A medium to large town&quot; &quot;A city or city suburb&quot; &quot;A medium to large town&quot; &quot;A medium to large town&quot; ... ## $ Q50a_NeighbourhoodNoise : chr &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; ... ## $ Q50b_NeighbourhoodAir : chr &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; ... ## $ Q50c_NeighbourhoodWater : chr &quot;Major problems&quot; &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; ... ## $ Q50d_NeighbourhoodCrime : chr &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; ... ## $ Q50e_NeighbourhoodLitter : chr &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; ... ## $ Q50f_NeighbourhoodTraffic : chr &quot;No problems&quot; &quot;No problems&quot; &quot;No problems&quot; &quot;Moderate problems&quot; ... ## $ Q51a_AccServicesPost : chr &quot;Service not used&quot; &quot;Easily&quot; &quot;Easily&quot; &quot;Easily&quot; ... ## $ Q51b_AccServicesBank : chr &quot;Easily&quot; &quot;With some difficulty&quot; &quot;Easily&quot; &quot;Easily&quot; ... ## $ Q53c_QualityPublicTransport : chr &quot;6&quot; &quot;7&quot; &quot;7&quot; &quot;6&quot; ... ## $ Income_PPP : num NA 273 3191 4172 478 ... The head code shows the first 6 rows and all the columns (variables) in the dataset. Meanwhile the str code shows the information of the dataset, such as what format type each column/variable is, how many observations, etc. B. Using RStudio Go to Environment Click Import Dataset Choose From Text (base) or From Test (readr) Click Browse and select your .csv file Click Import RStudio will load the dataset and generate R code in Console. Copy the R code to your script for reproducibility. 6.2.3.2 Importing an Excel File First, install and load the package: install.packages(&quot;readxl&quot;) library(readxl) cp_xlsx&lt;-read_excel(&quot;CP_1.xlsx&quot;) If you only want a particular sheet to be imported, cp_xlsx&lt;-read_excel(&quot;CP_1.xlsx&quot;, sheet= 1) head(cp_xlsx) ## # A tibble: 6 × 49 ## Country ID HH1_Num_People HH2a_Sex HH2b_Age HH2d_EmploymentSitua…¹ Q1_PaidJob Q2_Empoyment ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Bulgaria BG15… 3 Female 56 Unemployed less than … Yes &lt;NA&gt; ## 2 Netherl… NL51… 1 Female 20 In education (at scho… Yes &lt;NA&gt; ## 3 Netherl… NL50… 2 Male 63 Retired Yes &lt;NA&gt; ## 4 Slovenia SI10… 3 Male 63 At work as employee o… &lt;NA&gt; Employed ## 5 Bulgaria BG13… 2 Male 89 Retired Yes &lt;NA&gt; ## 6 Slovakia SK11… 2 Female 44 At work as employee o… &lt;NA&gt; Self-employ… ## # ℹ abbreviated name: ¹​HH2d_EmploymentSituation ## # ℹ 41 more variables: Q3_Contract &lt;chr&gt;, Q4_Occupation &lt;chr&gt;, Q7_HoursWeekWork &lt;dbl&gt;, ## # Q7a_AdditionalJob &lt;chr&gt;, Q7b_HoursWeekWeekAddJob &lt;dbl&gt;, Q7c_Work &lt;chr&gt;, ## # Q8_HoursWeekWorkPref &lt;dbl&gt;, Q9_HoursWeekWorkPartner &lt;dbl&gt;, ## # Q10_HoursWeekWorkPartnerPref &lt;dbl&gt;, Q17_Rooms &lt;dbl&gt;, Q18_Tenancy &lt;chr&gt;, ## # Q19a_ShortageSpace &lt;dbl&gt;, Q19b_Rot &lt;dbl&gt;, Q19c_Leaks &lt;dbl&gt;, Q19d_NoFlusingToilet &lt;dbl&gt;, ## # Q19e_NoBathShower &lt;dbl&gt;, Q19f_NoOutside &lt;dbl&gt;, Q20_LeaveAccomodation_NoAff &lt;chr&gt;, … B. Using RStudio Go to Environment Click Import Dataset Choose From Excel Click Browse and select your .xlsx file Choose the sheet Click Import Check that you also have the variables as the header. 6.2.3.3 Importing RData These files are native to R and can contain multiple objects. load(&quot;Dataset_CP.RData&quot;) head(Dataset_CP) ## # A tibble: 6 × 49 ## Country ID HH1_Num_People HH2a_Sex HH2b_Age HH2d_EmploymentSitua…¹ Q1_PaidJob Q2_Empoyment ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; ## 1 Bulgaria BG15… 3 Female 56 Unemployed less than … Yes &lt;NA&gt; ## 2 Netherl… NL51… 1 Female 20 In education (at scho… Yes &lt;NA&gt; ## 3 Netherl… NL50… 2 Male 63 Retired Yes &lt;NA&gt; ## 4 Slovenia SI10… 3 Male 63 At work as employee o… &lt;NA&gt; Employed ## 5 Bulgaria BG13… 2 Male 89 Retired Yes &lt;NA&gt; ## 6 Slovakia SK11… 2 Female 44 At work as employee o… &lt;NA&gt; Self-employ… ## # ℹ abbreviated name: ¹​HH2d_EmploymentSituation ## # ℹ 41 more variables: Q3_Contract &lt;fct&gt;, Q4_Occupation &lt;fct&gt;, Q7_HoursWeekWork &lt;dbl&gt;, ## # Q7a_AdditionalJob &lt;fct&gt;, Q7b_HoursWeekWeekAddJob &lt;dbl&gt;, Q7c_Work &lt;fct&gt;, ## # Q8_HoursWeekWorkPref &lt;dbl&gt;, Q9_HoursWeekWorkPartner &lt;dbl&gt;, ## # Q10_HoursWeekWorkPartnerPref &lt;dbl&gt;, Q17_Rooms &lt;dbl&gt;, Q18_Tenancy &lt;fct&gt;, ## # Q19a_ShortageSpace &lt;dbl&gt;, Q19b_Rot &lt;dbl&gt;, Q19c_Leaks &lt;dbl&gt;, Q19d_NoFlusingToilet &lt;dbl&gt;, ## # Q19e_NoBathShower &lt;dbl&gt;, Q19f_NoOutside &lt;dbl&gt;, Q20_LeaveAccomodation_NoAff &lt;fct&gt;, … B. Using RStudio Environment panel Click Import Dataset Choose From RData Select the .RData file Click Import 6.3 Data Cleaning As you can see, there are 49 columns. Let’s simplify and work with fewer variables relevant for analysis. We can do this using the select() function in dplyr. We will save them into a new data frame, ch2_p1.1. library(dplyr) ch2_p1.1&lt;-select(cp_csv, Country, ID, HH2a_Sex, HH2b_Age, Q1_PaidJob, Q7_HoursWeekWork, Q17_Rooms, Q49_Area, Income_PPP) select(df, var1, var2,...) keeps only the listed columns and removes the rest. 6.3.1 Renaming the Variables We will edit the names to much easier conventions. First, let us say that we just want to change them to lowercase names. names(ch2_p1.1)&lt;-tolower(names(ch2_p1.1)) Inspect: head(ch2_p1.1) ## country id hh2a_sex hh2b_age q1_paidjob q7_hoursweekwork q17_rooms ## 1 Bulgaria BG1535216 Female 56 Yes NA 3 ## 2 Netherlands NL5130211 Female 20 Yes NA 1 ## 3 Netherlands NL5063519 Male 63 Yes NA 6 ## 4 Slovenia SI1042916 Male 63 &lt;NA&gt; 35 3 ## 5 Bulgaria BG1396625 Male 89 Yes NA 1 ## 6 Slovakia SK1184115 Female 44 &lt;NA&gt; 43 2 ## q49_area income_ppp ## 1 A medium to large town NA ## 2 A city or city suburb 273.4731 ## 3 A medium to large town 3190.5196 ## 4 A medium to large town 4171.6329 ## 5 A city or city suburb 478.3407 ## 6 A medium to large town 759.6961 Inspect again on your own. Let us rename specific columns: ch2_p1.1&lt;-ch2_p1.1 %&gt;% rename( sex = hh2a_sex, age = hh2b_age, paid_job = q1_paidjob, hours_work = q7_hoursweekwork, rooms = q17_rooms, area = q49_area, income = income_ppp ) Inspect on your own. names() simply gets or sets variable names. tolower is to simply change to small letters rename(new_name = old_name) changes a column’s name without touching data %&gt;% is the pipe operator: it passes the dataset from one function to the next. 6.3.2 Sorting Variables Let’s say, we want to arrange income. We will create a different data for this. We use arrange or desc in dplyr package #Sort dataset by income, ascending (default) ch2_p1sort&lt;-arrange(ch2_p1.1, income) #Sort dataset by income, descending ch2_p1sort_desc&lt;-arrange(ch2_p1.1, desc(income)) Inspect on your own. 6.3.2.1 Making our own data frame ch2_p2&lt;-data.frame( ch2_p2 = as.factor(c(&quot;$10,000&quot;, &quot;$20,500&quot;, &quot;$15,250&quot;, &quot;$30,000&quot;, &quot;$50,750&quot;)) ) c() stands for combine. We’re creating a vector of values. as.factor() converts the vector into a factor, that is a categorical variable not numbers. data.frame(...) creates a dataset in R. head(ch2_p2) ## ch2_p2 ## 1 $10,000 ## 2 $20,500 ## 3 $15,250 ## 4 $30,000 ## 5 $50,750 Let’s sort this: ch2_p2sort&lt;-arrange(ch2_p2) head(ch2_p2) ## ch2_p2 ## 1 $10,000 ## 2 $20,500 ## 3 $15,250 ## 4 $30,000 ## 5 $50,750 It did not work. The problem is, ch2_p2 is not numeric. We can check: class(ch2_p2$ch2_p2) ## [1] &quot;factor&quot; We need to make it into a numeric value but we have a , and $. We need to remove them. We use the str_replace function in the stringr package. library(stringr) ch2_p2$ch2_p2&lt;-str_replace( ch2_p2$ch2_p2, #column we want to edit pattern = &#39;,&#39;, #what to find replacement = &#39;&#39; #what to replace it with ) head(ch2_p2) ## ch2_p2 ## 1 $10000 ## 2 $20500 ## 3 $15250 ## 4 $30000 ## 5 $50750 Now, let us remove the dollar sign; usually, simply doing the same thing we did with the comma works, but, there are some symbols that are used as “special character”. To “force” R to replace the presence of ‘$’, we add two backslashes before the dollar sign. ch2_p2$ch2_p2&lt;-str_replace( ch2_p2$ch2_p2, pattern = &#39;\\\\$&#39;, replacement = &#39;&#39; ) Inspect on your own. Now, sort ch2_p2 on your own. We can see that it was arranged, however, take a look at the way ch2_p2 was encoded; it is not numeric. So, we need to change this. class(ch2_p2$ch2_p2) ## [1] &quot;character&quot; Change to numeric through as.numeric() ch2_p2$ch2_p2&lt;-as.numeric(ch2_p2$ch2_p2) Inspect on your own. 6.3.3 Pipe Operator %&gt;% allows functions to be chained; it can be read as “then” - it tells R to do whatever comes after it to the stuff that comes before it. ch2_p1.1.2 &lt;- ch2_p1.1 %&gt;% filter(age &gt; 60) %&gt;% arrange(desc(income)) Inspect on your own. 6.3.4 Adding columns We will be using the pipe operator and the mutate to add a new column to ch2_p1.1 ch2_p1.1 &lt;- ch2_p1.1 %&gt;% mutate( #adds a new column to the dataset room_group = case_when( #checks each row&#39;s value and assigned a category rooms == 1 ~ &quot;one_room&quot;, rooms == 2 ~ &quot;two_rooms&quot;, rooms == 3 ~ &quot;three_rooms&quot;, rooms == 4 ~ &quot;four_rooms&quot;, rooms == 5 ~ &quot;five_rooms&quot;, rooms == 6 ~ &quot;six_rooms&quot;, rooms == 7 ~ &quot;seven_rooms&quot;, rooms == 8 ~ &quot;eight_rooms&quot;, rooms == 9 ~ &quot;nine_rooms&quot;, rooms == 10 ~ &quot;ten_rooms&quot;, rooms == 11 ~ &quot;eleven_rooms&quot;, rooms == 12 ~ &quot;twelve_rooms&quot;, TRUE ~ &quot;other&quot; # anything outside 1–12 or missing ) ) 6.3.5 Transforming Values Now, you can see that paid_job is a character that is “yes/no”. We need to change that to numeric value. This is particularly useful when we use dummy variables later on. We will not use case_when as it is not necessary; rather, we will use ifelse: ch2_p1.1&lt;-ch2_p1.1 %&gt;% mutate( paid_job = ifelse(paid_job == &quot;Yes&quot;, 1, 0) ) 6.3.6 Categorizing into groups We use the case_when(): ch2_p1.1 &lt;- ch2_p1.1 %&gt;% mutate( age_group = case_when( age &gt;= 18 &amp; age &lt;= 29 ~ &quot;young&quot;, # 18–29 years age &gt;= 30 &amp; age &lt;= 59 ~ &quot;adult&quot;, # 30–59 years age &gt;= 60 ~ &quot;older_adult&quot;, # 60+ years TRUE ~ &quot;other&quot; # NA ) ) mutate() adding new column The conditions are important. 6.3.7 Summarizing Let us get the average of income by age group, which we’ll call ave_income, by using the group_by() and summarise() functions in dplyr ch2_p1.1ave&lt;-ch2_p1.1 %&gt;% group_by(age_group) %&gt;% #group by age group, THEN summarise(ave_income=mean(income)) #calculate the mean of income for each age group head(ch2_p1.1ave) ## # A tibble: 3 × 2 ## age_group ave_income ## &lt;chr&gt; &lt;dbl&gt; ## 1 adult NA ## 2 older_adult NA ## 3 young NA How did this happen? It is because there are NAs in income. Let’s check for NAs in our dataset colSums(is.na(ch2_p1.1)) ## country id sex age paid_job hours_work rooms area ## 0 0 0 0 1768 2304 25 0 ## income room_group age_group ## 978 0 0 There are 978 NAs in income, that is why the average income is NA. For the sake of, let’s remove the NA. ch2_p1.1ave &lt;- ch2_p1.1 %&gt;% group_by(age_group) %&gt;% summarise(ave_income = mean(income, na.rm = TRUE)) head(ch2_p1.1ave) ## # A tibble: 3 × 2 ## age_group ave_income ## &lt;chr&gt; &lt;dbl&gt; ## 1 adult 2145. ## 2 older_adult 1566. ## 3 young 1809. The difference is the inclusion of na.rm = TRUE which means we remove the missing values when calculating the mean. So, even though we know income is numeric, the presence of NA causes the output when calculating mean, sd, etc. become NA too. 6.3.8 Merging datasets We have two main datasets, ch2_p1.1 and ch2_p1.1ave. By doing this, we could compare side-by-side each observation compared to the average per age group. We will join the datasets by age_group variable, since that is consistent across both datasets. We name the new file as ch2_p1merged: ch2_p1merged&lt;-merge(x=ch2_p1.1, y=ch2_p1.1ave, by=&quot;age_group&quot;) head(ch2_p1merged) ## age_group country id sex age paid_job hours_work rooms area ## 1 adult Bulgaria BG1535216 Female 56 1 NA 3 A medium to large town ## 2 adult Hungary HU1042815 Male 39 0 NA 2 A village/small town ## 3 adult Poland PL1229721 Female 47 NA 40 4 A village/small town ## 4 adult Germany DE1045717 Female 56 1 NA 3 A city or city suburb ## 5 adult Finland FI1024310 Male 58 NA 32 5 A medium to large town ## 6 adult Slovakia SK1184115 Female 44 NA 43 2 A medium to large town ## income room_group ave_income ## 1 NA three_rooms 2145.059 ## 2 987.0490 two_rooms 2145.059 ## 3 1722.0737 four_rooms 2145.059 ## 4 NA three_rooms 2145.059 ## 5 3958.9271 five_rooms 2145.059 ## 6 759.6961 two_rooms 2145.059 6.3.9 Splitting datasets Say I want to save different datasets based on the age_group column. adult_data&lt;-ch2_p1.1 %&gt;% filter(age_group==&quot;adult&quot;) filter() keeps rows that meet the condition. You can save it as a .csv file: write.csv(adult_data, &quot;adult_data.csv&quot;, row.names = FALSE) Can you do the others? (young or older_adult) 6.3.10 Reshaping Datasets Let’s say you want to reshape income and hours_work into a long format so every row is a variable measurement. We need both tidyr and dplyr packages. 6.3.10.1 Long Format library(tidyr) library(dplyr) ch2_long&lt;-ch2_p1.1 %&gt;% pivot_longer( cols = c(hours_work, income), # columns to stack names_to = &quot;variable&quot;, #new column for variable names values_to = &quot;value&quot; #new column for their values ) head(ch2_long) ## # A tibble: 6 × 11 ## country id sex age paid_job rooms area room_group age_group variable value ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Bulgaria BG1535216 Female 56 1 3 A mediu… three_roo… adult hours_w… NA ## 2 Bulgaria BG1535216 Female 56 1 3 A mediu… three_roo… adult income NA ## 3 Netherlands NL5130211 Female 20 1 1 A city … one_room young hours_w… NA ## 4 Netherlands NL5130211 Female 20 1 1 A city … one_room young income 273. ## 5 Netherlands NL5063519 Male 63 1 6 A mediu… six_rooms older_ad… hours_w… NA ## 6 Netherlands NL5063519 Male 63 1 6 A mediu… six_rooms older_ad… income 3191. pivot_longer() turns columns into rows 6.3.10.2 Wide Format ch2_wide&lt;-ch2_long %&gt;% pivot_wider( names_from = variable, #column to spread to multiple columns values_from = value #value to fill columns ) head(ch2_wide) ## # A tibble: 6 × 11 ## country id sex age paid_job rooms area room_group age_group hours_work income ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Bulgaria BG1535216 Female 56 1 3 A me… three_roo… adult NA NA ## 2 Netherlands NL5130211 Female 20 1 1 A ci… one_room young NA 273. ## 3 Netherlands NL5063519 Male 63 1 6 A me… six_rooms older_ad… NA 3191. ## 4 Slovenia SI1042916 Male 63 NA 3 A me… three_roo… older_ad… 35 4172. ## 5 Bulgaria BG1396625 Male 89 1 1 A ci… one_room older_ad… NA 478. ## 6 Slovakia SK1184115 Female 44 NA 2 A me… two_rooms adult 43 760. Say you want to analyze repeated categories or measures. We can pivot the room_group and age_group to long: ch2_long2&lt;-ch2_p1.1 %&gt;% pivot_longer( cols = c(room_group, age_group), names_to = &quot;category&quot;, values_to = &quot;group&quot; ) head(ch2_long2) ## # A tibble: 6 × 11 ## country id sex age paid_job hours_work rooms area income category group ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Bulgaria BG1535216 Female 56 1 NA 3 A medium t… NA room_gr… thre… ## 2 Bulgaria BG1535216 Female 56 1 NA 3 A medium t… NA age_gro… adult ## 3 Netherlands NL5130211 Female 20 1 NA 1 A city or … 273. room_gr… one_… ## 4 Netherlands NL5130211 Female 20 1 NA 1 A city or … 273. age_gro… young ## 5 Netherlands NL5063519 Male 63 1 NA 6 A medium t… 3191. room_gr… six_… ## 6 Netherlands NL5063519 Male 63 1 NA 6 A medium t… 3191. age_gro… olde… 6.3.11 Missing Values We already did it before but just to remind: #Count missing values per column colSums(is.na(ch2_p1.1)) ## country id sex age paid_job hours_work rooms area ## 0 0 0 0 1768 2304 25 0 ## income room_group age_group ## 978 0 0 When there are missing values, it reduces sample size, can bias estimates if the missingness is not random and may introduce endogeneity if the missing data is correlated with the outcome or other variables. 6.3.11.1 Types of Missing Data MCAR - Missing Completely at Random Missingness is unrelated to anything in the data MAR - Missing at Random Missingness depends on observed variables but not on the missing value itself. Example: younger respondents are less likely to report income. MNAR - Missing Not at Random Missingness depends on the value itself Example: high income people refuse to report income If you have MCAR, safe to remove this. If MAR or MNAR, removing these can cause bias. If a variable with missing values affects the outcome and you remove it or impute incorrectly, you can create endogeneity. 6.3.11.2 Handling Missing Values 6.3.11.2.1 a. Remove missing observations #Keep only rows without missing income ch2_p1.2&lt;-ch2_p1.1 %&gt;% filter(!is.na(income)) !is.na() means you are keeping rows WITHOUT missing income Again, double-check because removing the missing values may bias your results 6.3.11.2.2 b. Replace missing values (imputation of mean/median) #replace missing income with the mean ch2_p1.3&lt;-ch2_p1.1 %&gt;% mutate(income=ifelse(is.na(income), mean(income, na.rm=TRUE), income)) ifelse(condition, value_if_true, value_if_false) in this case, you are telling R to search income’s NA values, if there are NA values, calculate the mean income without the NAs. then, change the NAs with the calculated mean income, otherwise, keep the income as is. There are advanced methods but will not be discussed. You have to be careful and always check for missing data. 6.4 Closing Quiz questions will be uploaded in Animospace. You have 15 minutes to answer. Clean the environment and free the memory. "],["data-management---time-series-and-panel-data.html", "7 Data Management - Time Series and Panel Data 7.1 Time Series Data 7.2 Panel Data 7.3 Closing", " 7 Data Management - Time Series and Panel Data 7.1 Time Series Data Time series analysis requires correct date formats, proper chronological ordering, etc. For this, we will use Chapter3 Practice found in the Modules. 7.1.1 Preliminaries Always remember the first steps: Set Working Directory and Clean the Global Environment. rm(list=ls()) gc() ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 2972560 158.8 5811240 310.4 5811240 310.4 ## Vcells 6393370 48.8 12255594 93.6 11855270 90.5 To make sure that you are using the correct directory and that you have all the files you need, use list.files() function. list.files() Now, we load the following packages: dplyr, lubridate, and zoo. Make sure you have all 3 installed; if not, install them. library(dplyr) library(lubridate) library(zoo) ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric 7.1.2 Create a Simple Date Dataset date_date&lt;-data.frame( ID = 1:5, dob = c(&quot;15-05-1990&quot;, &quot;20-08-1985&quot;, &quot;01-12-2000&quot;, &quot;10-03-1995&quot;, &quot;25-07-2010&quot;), stringsAsFactors = FALSE ) print(date_date) ## ID dob ## 1 1 15-05-1990 ## 2 2 20-08-1985 ## 3 3 01-12-2000 ## 4 4 10-03-1995 ## 5 5 25-07-2010 str(date_date) ## &#39;data.frame&#39;: 5 obs. of 2 variables: ## $ ID : int 1 2 3 4 5 ## $ dob: chr &quot;15-05-1990&quot; &quot;20-08-1985&quot; &quot;01-12-2000&quot; &quot;10-03-1995&quot; ... I won’t repeat what the code has except for new ones like ID which creates a numeric sequence for the ID column. date_of_birth = c(\"15-05-1990\",...) are dates stored as character strings. stringsAsFactors = FALSE because R sometimes turns text into factors (categories) so by making it FALSE, it ensures dates remain character strings not categories As seen, the dob is in character format: 7.1.3 Converting Character Dates to Date Format date_date$dob&lt;- as.Date( date_date$dob, format = &quot;%d-%m-%Y&quot; ) class(date_date$dob) ## [1] &quot;Date&quot; So, we converted character strings into Date objects. With this, we can calculate age, lags, etc. 7.1.4 Calculate Age: Say you want to calculate the age: Before, we added columns through mutate; this time, we add columns through creating a new object. date_date$age &lt;- as.numeric(floor((Sys.Date()-date_date$dob)/365.25)) as.Date() converts strings to dates while floor() simply rounds down. 7.1.4.1 Custom Reference Date: ref_date&lt;-as.Date(&quot;2020-12-20&quot;) #uses YYYY-MM-DD as ISO standard that R recognizes immediately date_date$age2&lt;- as.numeric( floor((ref_date-date_date$dob)/365.25) ) 7.1.5 Using Time Series Data We load Daily Bitcoin Data ch3_p1&lt;-read.csv(&quot;Ch3Practice.csv&quot;) head(ch3_p1) ## ds y ## 1 2015-06-13 232.402 ## 2 2015-06-14 233.543 ## 3 2015-06-15 236.823 ## 4 2015-06-16 250.895 ## 5 2015-06-17 249.284 ## 6 2015-06-18 249.007 We need to understand our data; str(ch3_p1) ## &#39;data.frame&#39;: 1825 obs. of 2 variables: ## $ ds: chr &quot;2015-06-13&quot; &quot;2015-06-14&quot; &quot;2015-06-15&quot; &quot;2015-06-16&quot; ... ## $ y : num 232 234 237 251 249 ... 7.1.6 Convert to Date Format As you can see, our ds is what our date column is, however, it is in the character format. We need to convert it to the Date class. We also need to do this to a copy of the raw data for further modifications. ch3_p1.1&lt;-ch3_p1 head(ch3_p1.1$ds) ## [1] &quot;2015-06-13&quot; &quot;2015-06-14&quot; &quot;2015-06-15&quot; &quot;2015-06-16&quot; &quot;2015-06-17&quot; &quot;2015-06-18&quot; class(ch3_p1.1$ds) ## [1] &quot;character&quot; ch3_p1.1$ds &lt;- as.Date(ch3_p1.1$ds, format = &quot;%Y-%m-%d&quot;) class(ch3_p1.1$ds) ## [1] &quot;Date&quot; 7.1.7 Aggregate Data We now have daily data. Say we want to create weekly data, we use the cut function to group dates by week, month, quarter and year. Since we know for sure that the date column is in date format, no need to check, however, it is always useful to check the class of date. 7.1.7.1 Aggregate by Week Add new columns for each aggregation. ch3_p1.1$week&lt;-cut(ch3_p1.1$ds, breaks = &quot;week&quot;) The cut is used to divide the date into intervals while the breaks specifies that the date be divided into weekly intervals. Check creation of the week column head(ch3_p1.1) ## ds y week ## 1 2015-06-13 232.402 2015-06-08 ## 2 2015-06-14 233.543 2015-06-08 ## 3 2015-06-15 236.823 2015-06-15 ## 4 2015-06-16 250.895 2015-06-15 ## 5 2015-06-17 249.284 2015-06-15 ## 6 2015-06-18 249.007 2015-06-15 Since we have the y column which is actually Bitcoin Price, we need to aggregate that weekly using the aggregate function week_y&lt;-aggregate(y ~ week, #refers to column for bitcoin data=ch3_p1.1, FUN = mean #specifies that the mean function should be applied to the numeric column within each week ) You will notice that this creates a separate data frame. We will merge week_y with ch3_p1.1 ch3_p1.1&lt;-merge(ch3_p1.1, week_y, by = &quot;week&quot;, #ensures the merge aligns based on the week suffixes = c(&quot;&quot;,&quot;_weekly&quot;)) #adds _weekly to the column name to distinguish them from the original columns We will slightly do the same thing when aggregating by month, quarter and year. I will do the initial steps, but please do the succeeding steps on your own. 7.1.7.2 Aggregate by Month # Add a month column ch3_p1.1$month &lt;- format(ch3_p1.1$ds, &quot;%Y-%m&quot;) # Calculate monthly means month_y &lt;- aggregate(y ~ month, data = ch3_p1.1, FUN = mean) Do the next steps as well as inspection on your own. 7.1.7.3 Aggregate by Quarter This is different since we will use the paste0 and the format functions. The format function extracts the year from the date and extracts the quarter from the date. The paste0 combines the year and quarter without a space between them so that it results in which quarter of which year. ch3_p1.1$quarter &lt;- paste0(format(ch3_p1.1$ds, &quot;%Y&quot;), &quot; &quot;, quarters(ch3_p1.1$ds)) 7.1.7.4 Aggregate by Year ch3_p1.1$year&lt;-format(ch3_p1.1$ds, &quot;%Y&quot;) Can you aggregate the Bitcoin values quarterly and yearly on your own with inspection? 7.2 Panel Data We will use a package in R containing different datasets. if(!(&quot;wooldridge&quot; %in% installed.packages()[,&quot;Package&quot;])) install.packages(&quot;wooldridge&quot;) library(wooldridge) data(&quot;wagepan&quot;) Unlike importing CSV, Excel or RData, since the data is found in a package, we call for the data through loading the package then data(\"dataset_name\"). The dataset will appear in the environment. str(wagepan) ## &#39;data.frame&#39;: 4360 obs. of 44 variables: ## $ nr : int 13 13 13 13 13 13 13 13 17 17 ... ## $ year : int 1980 1981 1982 1983 1984 1985 1986 1987 1980 1981 ... ## $ agric : int 0 0 0 0 0 0 0 0 0 0 ... ## $ black : int 0 0 0 0 0 0 0 0 0 0 ... ## $ bus : int 1 0 1 1 0 1 1 1 0 0 ... ## $ construc: int 0 0 0 0 0 0 0 0 0 0 ... ## $ ent : int 0 0 0 0 0 0 0 0 0 0 ... ## $ exper : int 1 2 3 4 5 6 7 8 4 5 ... ## $ fin : int 0 0 0 0 0 0 0 0 0 0 ... ## $ hisp : int 0 0 0 0 0 0 0 0 0 0 ... ## $ poorhlth: int 0 0 0 0 0 0 0 0 0 0 ... ## $ hours : int 2672 2320 2940 2960 3071 2864 2994 2640 2484 2804 ... ## $ manuf : int 0 0 0 0 0 0 0 0 0 0 ... ## $ married : int 0 0 0 0 0 0 0 0 0 0 ... ## $ min : int 0 0 0 0 0 0 0 0 0 0 ... ## $ nrthcen : int 0 0 0 0 0 0 0 0 0 0 ... ## $ nrtheast: int 1 1 1 1 1 1 1 1 1 1 ... ## $ occ1 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ2 : int 0 0 0 0 0 1 1 1 1 1 ... ## $ occ3 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ4 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ5 : int 0 0 0 0 1 0 0 0 0 0 ... ## $ occ6 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ7 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ8 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ9 : int 1 1 1 1 0 0 0 0 0 0 ... ## $ per : int 0 1 0 0 1 0 0 0 0 0 ... ## $ pro : int 0 0 0 0 0 0 0 0 0 0 ... ## $ pub : int 0 0 0 0 0 0 0 0 0 0 ... ## $ rur : int 0 0 0 0 0 0 0 0 0 0 ... ## $ south : int 0 0 0 0 0 0 0 0 0 0 ... ## $ educ : int 14 14 14 14 14 14 14 14 13 13 ... ## $ tra : int 0 0 0 0 0 0 0 0 0 0 ... ## $ trad : int 0 0 0 0 0 0 0 0 1 1 ... ## $ union : int 0 1 0 0 0 0 0 0 0 0 ... ## $ lwage : num 1.2 1.85 1.34 1.43 1.57 ... ## $ d81 : int 0 1 0 0 0 0 0 0 0 1 ... ## $ d82 : int 0 0 1 0 0 0 0 0 0 0 ... ## $ d83 : int 0 0 0 1 0 0 0 0 0 0 ... ## $ d84 : int 0 0 0 0 1 0 0 0 0 0 ... ## $ d85 : int 0 0 0 0 0 1 0 0 0 0 ... ## $ d86 : int 0 0 0 0 0 0 1 0 0 0 ... ## $ d87 : int 0 0 0 0 0 0 0 1 0 0 ... ## $ expersq : int 1 4 9 16 25 36 49 64 16 25 ... ## - attr(*, &quot;time.stamp&quot;)= chr &quot;25 Jun 2011 23:03&quot; In practice, it is best to leave the raw dataset untouched. Create a copy of the dataset and that is where you do modifications. ch3_p2&lt;-wagepan str(ch3_p2) ## &#39;data.frame&#39;: 4360 obs. of 44 variables: ## $ nr : int 13 13 13 13 13 13 13 13 17 17 ... ## $ year : int 1980 1981 1982 1983 1984 1985 1986 1987 1980 1981 ... ## $ agric : int 0 0 0 0 0 0 0 0 0 0 ... ## $ black : int 0 0 0 0 0 0 0 0 0 0 ... ## $ bus : int 1 0 1 1 0 1 1 1 0 0 ... ## $ construc: int 0 0 0 0 0 0 0 0 0 0 ... ## $ ent : int 0 0 0 0 0 0 0 0 0 0 ... ## $ exper : int 1 2 3 4 5 6 7 8 4 5 ... ## $ fin : int 0 0 0 0 0 0 0 0 0 0 ... ## $ hisp : int 0 0 0 0 0 0 0 0 0 0 ... ## $ poorhlth: int 0 0 0 0 0 0 0 0 0 0 ... ## $ hours : int 2672 2320 2940 2960 3071 2864 2994 2640 2484 2804 ... ## $ manuf : int 0 0 0 0 0 0 0 0 0 0 ... ## $ married : int 0 0 0 0 0 0 0 0 0 0 ... ## $ min : int 0 0 0 0 0 0 0 0 0 0 ... ## $ nrthcen : int 0 0 0 0 0 0 0 0 0 0 ... ## $ nrtheast: int 1 1 1 1 1 1 1 1 1 1 ... ## $ occ1 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ2 : int 0 0 0 0 0 1 1 1 1 1 ... ## $ occ3 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ4 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ5 : int 0 0 0 0 1 0 0 0 0 0 ... ## $ occ6 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ7 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ8 : int 0 0 0 0 0 0 0 0 0 0 ... ## $ occ9 : int 1 1 1 1 0 0 0 0 0 0 ... ## $ per : int 0 1 0 0 1 0 0 0 0 0 ... ## $ pro : int 0 0 0 0 0 0 0 0 0 0 ... ## $ pub : int 0 0 0 0 0 0 0 0 0 0 ... ## $ rur : int 0 0 0 0 0 0 0 0 0 0 ... ## $ south : int 0 0 0 0 0 0 0 0 0 0 ... ## $ educ : int 14 14 14 14 14 14 14 14 13 13 ... ## $ tra : int 0 0 0 0 0 0 0 0 0 0 ... ## $ trad : int 0 0 0 0 0 0 0 0 1 1 ... ## $ union : int 0 1 0 0 0 0 0 0 0 0 ... ## $ lwage : num 1.2 1.85 1.34 1.43 1.57 ... ## $ d81 : int 0 1 0 0 0 0 0 0 0 1 ... ## $ d82 : int 0 0 1 0 0 0 0 0 0 0 ... ## $ d83 : int 0 0 0 1 0 0 0 0 0 0 ... ## $ d84 : int 0 0 0 0 1 0 0 0 0 0 ... ## $ d85 : int 0 0 0 0 0 1 0 0 0 0 ... ## $ d86 : int 0 0 0 0 0 0 1 0 0 0 ... ## $ d87 : int 0 0 0 0 0 0 0 1 0 0 ... ## $ expersq : int 1 4 9 16 25 36 49 64 16 25 ... ## - attr(*, &quot;time.stamp&quot;)= chr &quot;25 Jun 2011 23:03&quot; 7.2.1 Sorting Panel Data We need to sort panel data so that they are ordered by individual (id), then time. This will help you when you do lags and differences. ch3_p2&lt;-ch3_p2 %&gt;% arrange(nr, year) head(ch3_p2) ## nr year agric black bus construc ent exper fin hisp poorhlth hours manuf married min nrthcen ## 1 13 1980 0 0 1 0 0 1 0 0 0 2672 0 0 0 0 ## 2 13 1981 0 0 0 0 0 2 0 0 0 2320 0 0 0 0 ## 3 13 1982 0 0 1 0 0 3 0 0 0 2940 0 0 0 0 ## 4 13 1983 0 0 1 0 0 4 0 0 0 2960 0 0 0 0 ## 5 13 1984 0 0 0 0 0 5 0 0 0 3071 0 0 0 0 ## 6 13 1985 0 0 1 0 0 6 0 0 0 2864 0 0 0 0 ## nrtheast occ1 occ2 occ3 occ4 occ5 occ6 occ7 occ8 occ9 per pro pub rur south educ tra trad ## 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 14 0 0 ## 2 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 14 0 0 ## 3 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 14 0 0 ## 4 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 14 0 0 ## 5 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 14 0 0 ## 6 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 14 0 0 ## union lwage d81 d82 d83 d84 d85 d86 d87 expersq ## 1 0 1.197540 0 0 0 0 0 0 0 1 ## 2 1 1.853060 1 0 0 0 0 0 0 4 ## 3 0 1.344462 0 1 0 0 0 0 0 9 ## 4 0 1.433213 0 0 1 0 0 0 0 16 ## 5 0 1.568125 0 0 0 1 0 0 0 25 ## 6 0 1.699891 0 0 0 0 1 0 0 36 7.2.2 Checking Panel Balance When using panel data, checking for a balanced panel is necessary to know if every individual is observed every time period. An unbalanced panel means some individuals are missing years. This matters because many econometric assumptions rely on balance; such as selection bias in the sense that when you do not detect imbalance, you might miss events like firms exiting the market or respondents dropping out. table(table(ch3_p2$nr)) ## ## 8 ## 545 From the result, we know that each of the 545 individuals were observed 8 times. For unbalanced panel, you will see an output with multiple numbers as these indicate the missing periods and individuals. The table(table(id)) tells you whether each individual has the same amount of time in the panel. 7.2.3 Creating Lagged Variables We know that economic processes do not happen simultaneously, that is why it is important to use lags. Lags enforce causality, not correlation. In panel data, lags are within-individual; So, the question you are trying to answer here is: “How did this individual’s past outcome affect this person’s current outcome?” When using the Fixed Effects which rely on within-unit variation over time, lag adjustments are needed because without them, fixed effects would not work. ch3_p2&lt;-ch3_p2 %&gt;% group_by(nr) %&gt;% mutate(lwage_lag = lag(lwage)) head(ch3_p2) ## # A tibble: 6 × 45 ## # Groups: nr [1] ## nr year agric black bus construc ent exper fin hisp poorhlth hours manuf married ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 13 1980 0 0 1 0 0 1 0 0 0 2672 0 0 ## 2 13 1981 0 0 0 0 0 2 0 0 0 2320 0 0 ## 3 13 1982 0 0 1 0 0 3 0 0 0 2940 0 0 ## 4 13 1983 0 0 1 0 0 4 0 0 0 2960 0 0 ## 5 13 1984 0 0 0 0 0 5 0 0 0 3071 0 0 ## 6 13 1985 0 0 1 0 0 6 0 0 0 2864 0 0 ## # ℹ 31 more variables: min &lt;int&gt;, nrthcen &lt;int&gt;, nrtheast &lt;int&gt;, occ1 &lt;int&gt;, occ2 &lt;int&gt;, ## # occ3 &lt;int&gt;, occ4 &lt;int&gt;, occ5 &lt;int&gt;, occ6 &lt;int&gt;, occ7 &lt;int&gt;, occ8 &lt;int&gt;, occ9 &lt;int&gt;, ## # per &lt;int&gt;, pro &lt;int&gt;, pub &lt;int&gt;, rur &lt;int&gt;, south &lt;int&gt;, educ &lt;int&gt;, tra &lt;int&gt;, trad &lt;int&gt;, ## # union &lt;int&gt;, lwage &lt;dbl&gt;, d81 &lt;int&gt;, d82 &lt;int&gt;, d83 &lt;int&gt;, d84 &lt;int&gt;, d85 &lt;int&gt;, d86 &lt;int&gt;, ## # d87 &lt;int&gt;, expersq &lt;int&gt;, lwage_lag &lt;dbl&gt; It is important to do group_by because each individual has their own time line and the lags stay within individuals. Therefore, what this does is treating each individual as separate time series. 7.2.4 Missing Data in Panels colSums(is.na(ch3_p2)) ## nr year agric black bus construc ent exper fin ## 0 0 0 0 0 0 0 0 0 ## hisp poorhlth hours manuf married min nrthcen nrtheast occ1 ## 0 0 0 0 0 0 0 0 0 ## occ2 occ3 occ4 occ5 occ6 occ7 occ8 occ9 per ## 0 0 0 0 0 0 0 0 0 ## pro pub rur south educ tra trad union lwage ## 0 0 0 0 0 0 0 0 0 ## d81 d82 d83 d84 d85 d86 d87 expersq lwage_lag ## 0 0 0 0 0 0 0 0 545 ch3_p2.1&lt;-ch3_p2 %&gt;% filter(!is.na(lwage_lag)) 7.2.5 Creating Growth Rates ch3_p2 &lt;- ch3_p2 %&gt;% group_by(nr) %&gt;% mutate( wg = lwage - lag(lwage) ) head(ch3_p2$wg, 10) #due to number of cols, chose the one we just created and specified 10 observations ## [1] NA 0.65551984 -0.50859833 0.08875167 0.13491178 0.13176584 -2.42015356 ## [8] 2.38945049 NA -0.15756428 What we did was create within-individual wage growth over time. Remember our discussion on lag? It will answer: “How much did this individual’s wage change from the previous period?” Furthermore, we are doing dynamic analysis here. We also note that the first observation per person has no lag. 7.3 Closing Quiz questions will be uploaded in Animospace. You have 15 minutes to answer. Clean the environment and free the memory AFTER the quiz. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
